{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from torchvision.models import vit_b_16, vit_l_16\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_load = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_path = 'data/processed'\n",
    "# data_base_path = 'data/subset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(f'{data_base_path}/train/known', transform=simple_load)\n",
    "test_dataset = ImageFolder(f'{data_base_path}/test/known', transform=simple_load)\n",
    "val_dataset = ImageFolder(f'{data_base_path}/valid/known', transform=simple_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_resized(path: str):\n",
    "    image = torchvision.io.read_image(path)\n",
    "    resize = v2.Resize((224, 224))\n",
    "    bigger_image = resize(image)\n",
    "\n",
    "    return v2.ToPILImage()(bigger_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=224x224>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = f'./{data_base_path}/train/known/yes/004ae714_nohash_0.png'\n",
    "get_image_resized(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Model Resnet-18 not pretrained (random weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet(n_classes: int):\n",
    "    model_resnet = models.resnet18(pretrained=False)\n",
    "\n",
    "    output_features = model_resnet.fc.in_features \n",
    "    ## We have 512 output features, we have to add to model a fully connected layer for our \n",
    "    ## classification problem with only specified target classes\n",
    "    model_resnet.fc = nn.Linear(output_features, n_classes)\n",
    "    model_resnet = model_resnet.to(device)\n",
    "    return model_resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes: int):\n",
    "        super(CustomCRNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.rnn = nn.LSTM(input_size=64 * 21 * 21, hidden_size=256)\n",
    "        self.softmax = nn.Sequential(\n",
    "            nn.Linear(256, n_classes),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, obs) -> torch.Tensor:\n",
    "        out_conv = self.conv(obs)\n",
    "        out_conv_flat = self.flatten(out_conv)\n",
    "        out_rnn = self.rnn(out_conv_flat)[0]\n",
    "        out_proba = self.softmax(out_rnn)\n",
    "        return out_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer VIT-base-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vit_base():\n",
    "    vit_base = vit_b_16()\n",
    "    vit_base.to(device)\n",
    "    return vit_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer VIT-large-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vit_large():\n",
    "    vit_large = vit_l_16()\n",
    "    vit_large.to(device)\n",
    "    return vit_large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network: nn.Module, train_dataset: ImageFolder, valid_dataset: ImageFolder, batch_size: int,\n",
    "          loss_fn, optimizer: torch.optim.Optimizer, max_epochs: int,\n",
    "          save_name: str | None = None, verbosity_period=1) -> dict[str, list[float]]:\n",
    "    \"\"\"\n",
    "    Based on: https://alirezasamar.com/blog/2023/03/fine-tuning-pre-trained-resnet-18-model-image-classification-pytorch/\n",
    "\n",
    "    Returns:\n",
    "        training statstics\n",
    "    \"\"\"\n",
    "    train_loss_per_epoch: list[float] = []\n",
    "    train_accuracy_per_epoch: list[float] = []\n",
    "    valid_loss_per_epoch: list[float] = []\n",
    "    valid_accuracy_per_epoch: list[float] = []\n",
    "\n",
    "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        epoch = epoch + 1\n",
    "\n",
    "        # setup for training\n",
    "        network.train()\n",
    "        train_epoch_loss_sum = 0.0\n",
    "        train_epoch_true_count = 0\n",
    "\n",
    "        # training loop\n",
    "        for images, true_labels in train_data_loader:\n",
    "\n",
    "            # move to the device (especially necessary when using cuda)\n",
    "            images = images.to(device)\n",
    "            true_labels = true_labels.to(device)\n",
    "\n",
    "            # feed forward\n",
    "            optimizer.zero_grad()\n",
    "            pred_proba = network(images)\n",
    "\n",
    "            loss = loss_fn(pred_proba, true_labels)\n",
    "            # backpropagation and update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update current epoch's stats\n",
    "            train_epoch_loss_sum += loss.item() * images.size(0)\n",
    "            # calculate accuracy but only if no advanced augmentations are used\n",
    "            # this is because with advanced augmentations true_labels becomes\n",
    "            # probabilites of each class\n",
    "            pred_labels = torch.argmax(pred_proba, dim=1)\n",
    "            train_epoch_true_count += torch.sum(pred_labels == true_labels.data)\n",
    "\n",
    "        # calculate and update stats\n",
    "        curr_train_loss = float(train_epoch_loss_sum / len(train_dataset))\n",
    "        train_loss_per_epoch.append(curr_train_loss)\n",
    "        curr_train_accuracy = float(train_epoch_true_count.double() / len(train_dataset))\n",
    "        train_accuracy_per_epoch.append(curr_train_accuracy)\n",
    "\n",
    "        # setup for validation\n",
    "        network.eval()\n",
    "        valid_epoch_loss_sum = 0.0\n",
    "        valid_epoch_true_count = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # same as before but on validation data\n",
    "            for images, true_labels in valid_data_loader:\n",
    "                # move to device\n",
    "                images = images.to(device)\n",
    "                true_labels = true_labels.to(device)\n",
    "\n",
    "                # make a prediction\n",
    "                pred_proba = network(images)\n",
    "                pred_labels = torch.argmax(pred_proba, dim=1)\n",
    "                loss = loss_fn(pred_proba, true_labels)\n",
    "\n",
    "                # update stats\n",
    "                valid_epoch_loss_sum += loss.item() * images.size(0)\n",
    "                valid_epoch_true_count += torch.sum(pred_labels == true_labels.data)\n",
    "\n",
    "        # calculate and update stats\n",
    "        curr_valid_loss = float(valid_epoch_loss_sum / len(val_dataset))\n",
    "        curr_valid_acccuracy = float(valid_epoch_true_count.double() / len(val_dataset))\n",
    "        valid_loss_per_epoch.append(curr_valid_loss)\n",
    "        valid_accuracy_per_epoch.append(curr_valid_acccuracy)\n",
    "\n",
    "        # Verbosity\n",
    "        if  verbosity_period > 0 and epoch % verbosity_period == 0:\n",
    "            train_acc_text = ''\n",
    "            train_acc_text = f'Train accuracy: {curr_train_accuracy:.4f} | '\n",
    "            print(f'Epoch {epoch} completed! | '\n",
    "                  f'Train loss: {curr_train_loss:.4f} | '\n",
    "                  f'{train_acc_text}'\n",
    "                  f'Validation loss: {curr_valid_loss:.4f} | '\n",
    "                  f'Validation accuracy: {curr_valid_acccuracy:.4f}')\n",
    "\n",
    "    stats = {\n",
    "        'train_loss': train_loss_per_epoch,\n",
    "        'train_accuracy': train_accuracy_per_epoch,\n",
    "        'valid_loss': valid_loss_per_epoch,\n",
    "        'valid_accuracy': valid_accuracy_per_epoch,\n",
    "    }\n",
    "\n",
    "    # save network weights and stats at the end\n",
    "    if save_name is not None:\n",
    "        # prepare save dir\n",
    "        datetime_id = datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "        save_dir = os.path.join('.', 'saved', f'{save_name}_{datetime_id}')\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        # save network weights\n",
    "        model_path = os.path.join(save_dir, f'{save_name}.pth')\n",
    "        torch.save(network.state_dict(), model_path)\n",
    "        # save training stats\n",
    "        stats_path = os.path.join(save_dir, f'{save_name}.json')\n",
    "        with open(stats_path, 'w') as file:\n",
    "            json.dump(stats, file)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(network_fresh: nn.Module, path: str) -> None:\n",
    "    \"\"\"Loads saved weights to the given network\"\"\"\n",
    "    network_fresh.load_state_dict(torch.load(path, map_location=torch.device(device)))\n",
    "    network_fresh.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stats(path: str) -> dict[str, list[float]]:\n",
    "    with open(path) as file:\n",
    "        stats = json.load(file)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Resnet-18 not pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed! | Train loss: 0.4077 | Train accuracy: 0.8625 | Validation loss: 1.6580 | Validation accuracy: 0.5761\n",
      "Epoch 2 completed! | Train loss: 0.1520 | Train accuracy: 0.9486 | Validation loss: 0.1973 | Validation accuracy: 0.9305\n",
      "Epoch 3 completed! | Train loss: 0.1167 | Train accuracy: 0.9623 | Validation loss: 0.2974 | Validation accuracy: 0.9005\n",
      "Epoch 4 completed! | Train loss: 0.0963 | Train accuracy: 0.9680 | Validation loss: 0.1516 | Validation accuracy: 0.9454\n",
      "Epoch 5 completed! | Train loss: 0.0843 | Train accuracy: 0.9701 | Validation loss: 0.1597 | Validation accuracy: 0.9488\n",
      "Epoch 6 completed! | Train loss: 0.0646 | Train accuracy: 0.9777 | Validation loss: 0.1910 | Validation accuracy: 0.9305\n",
      "Epoch 7 completed! | Train loss: 0.0751 | Train accuracy: 0.9747 | Validation loss: 0.1250 | Validation accuracy: 0.9623\n",
      "Epoch 8 completed! | Train loss: 0.0476 | Train accuracy: 0.9835 | Validation loss: 0.1048 | Validation accuracy: 0.9696\n",
      "Epoch 9 completed! | Train loss: 0.0444 | Train accuracy: 0.9842 | Validation loss: 0.1392 | Validation accuracy: 0.9527\n",
      "Epoch 10 completed! | Train loss: 0.0628 | Train accuracy: 0.9799 | Validation loss: 0.2055 | Validation accuracy: 0.9401\n",
      "Epoch 11 completed! | Train loss: 0.0681 | Train accuracy: 0.9767 | Validation loss: 0.1114 | Validation accuracy: 0.9657\n",
      "Epoch 12 completed! | Train loss: 0.0268 | Train accuracy: 0.9915 | Validation loss: 0.1224 | Validation accuracy: 0.9648\n",
      "Epoch 13 completed! | Train loss: 0.0309 | Train accuracy: 0.9906 | Validation loss: 0.1932 | Validation accuracy: 0.9546\n",
      "Epoch 14 completed! | Train loss: 0.0409 | Train accuracy: 0.9872 | Validation loss: 0.1103 | Validation accuracy: 0.9662\n",
      "Epoch 15 completed! | Train loss: 0.0168 | Train accuracy: 0.9947 | Validation loss: 0.1630 | Validation accuracy: 0.9551\n",
      "Epoch 16 completed! | Train loss: 0.0121 | Train accuracy: 0.9964 | Validation loss: 0.1654 | Validation accuracy: 0.9556\n",
      "Epoch 17 completed! | Train loss: 0.0134 | Train accuracy: 0.9955 | Validation loss: 0.1863 | Validation accuracy: 0.9575\n",
      "Epoch 18 completed! | Train loss: 0.0131 | Train accuracy: 0.9956 | Validation loss: 0.1504 | Validation accuracy: 0.9619\n",
      "Epoch 19 completed! | Train loss: 0.0168 | Train accuracy: 0.9953 | Validation loss: 0.1346 | Validation accuracy: 0.9657\n",
      "Epoch 20 completed! | Train loss: 0.0252 | Train accuracy: 0.9918 | Validation loss: 0.1927 | Validation accuracy: 0.9464\n",
      "Epoch 21 completed! | Train loss: 0.0090 | Train accuracy: 0.9971 | Validation loss: 0.1312 | Validation accuracy: 0.9643\n",
      "Epoch 22 completed! | Train loss: 0.0045 | Train accuracy: 0.9991 | Validation loss: 0.1288 | Validation accuracy: 0.9676\n",
      "Epoch 23 completed! | Train loss: 0.0123 | Train accuracy: 0.9961 | Validation loss: 0.1355 | Validation accuracy: 0.9619\n",
      "Epoch 24 completed! | Train loss: 0.0046 | Train accuracy: 0.9988 | Validation loss: 0.2615 | Validation accuracy: 0.9507\n",
      "Epoch 25 completed! | Train loss: 0.0224 | Train accuracy: 0.9926 | Validation loss: 0.2271 | Validation accuracy: 0.9454\n",
      "Epoch 26 completed! | Train loss: 0.0124 | Train accuracy: 0.9968 | Validation loss: 0.2585 | Validation accuracy: 0.9474\n",
      "Epoch 27 completed! | Train loss: 0.0210 | Train accuracy: 0.9943 | Validation loss: 0.2908 | Validation accuracy: 0.9334\n",
      "Epoch 28 completed! | Train loss: 0.0091 | Train accuracy: 0.9972 | Validation loss: 0.1494 | Validation accuracy: 0.9657\n",
      "Epoch 29 completed! | Train loss: 0.0045 | Train accuracy: 0.9986 | Validation loss: 0.2138 | Validation accuracy: 0.9590\n",
      "Epoch 30 completed! | Train loss: 0.0405 | Train accuracy: 0.9885 | Validation loss: 0.1765 | Validation accuracy: 0.9590\n",
      "Epoch 31 completed! | Train loss: 0.0070 | Train accuracy: 0.9980 | Validation loss: 0.1448 | Validation accuracy: 0.9638\n",
      "Epoch 32 completed! | Train loss: 0.0009 | Train accuracy: 0.9999 | Validation loss: 0.1508 | Validation accuracy: 0.9681\n",
      "Epoch 33 completed! | Train loss: 0.0005 | Train accuracy: 0.9999 | Validation loss: 0.1524 | Validation accuracy: 0.9672\n",
      "Epoch 34 completed! | Train loss: 0.0002 | Train accuracy: 1.0000 | Validation loss: 0.1555 | Validation accuracy: 0.9662\n",
      "Epoch 35 completed! | Train loss: 0.0001 | Train accuracy: 1.0000 | Validation loss: 0.1538 | Validation accuracy: 0.9667\n",
      "Epoch 36 completed! | Train loss: 0.0018 | Train accuracy: 0.9995 | Validation loss: 0.1730 | Validation accuracy: 0.9590\n",
      "Epoch 37 completed! | Train loss: 0.0365 | Train accuracy: 0.9889 | Validation loss: 0.2582 | Validation accuracy: 0.9474\n",
      "Epoch 38 completed! | Train loss: 0.0116 | Train accuracy: 0.9962 | Validation loss: 0.2545 | Validation accuracy: 0.9488\n",
      "Epoch 39 completed! | Train loss: 0.0372 | Train accuracy: 0.9899 | Validation loss: 0.1462 | Validation accuracy: 0.9691\n",
      "Epoch 40 completed! | Train loss: 0.0026 | Train accuracy: 0.9995 | Validation loss: 0.1442 | Validation accuracy: 0.9681\n",
      "Epoch 41 completed! | Train loss: 0.0014 | Train accuracy: 0.9999 | Validation loss: 0.1483 | Validation accuracy: 0.9633\n",
      "Epoch 42 completed! | Train loss: 0.0003 | Train accuracy: 1.0000 | Validation loss: 0.1389 | Validation accuracy: 0.9672\n",
      "Epoch 43 completed! | Train loss: 0.0002 | Train accuracy: 1.0000 | Validation loss: 0.1443 | Validation accuracy: 0.9672\n",
      "Epoch 44 completed! | Train loss: 0.0193 | Train accuracy: 0.9943 | Validation loss: 0.1394 | Validation accuracy: 0.9599\n",
      "Epoch 45 completed! | Train loss: 0.0053 | Train accuracy: 0.9984 | Validation loss: 0.1298 | Validation accuracy: 0.9681\n",
      "Epoch 46 completed! | Train loss: 0.0034 | Train accuracy: 0.9991 | Validation loss: 0.1442 | Validation accuracy: 0.9643\n",
      "Epoch 47 completed! | Train loss: 0.0027 | Train accuracy: 0.9991 | Validation loss: 0.2226 | Validation accuracy: 0.9565\n",
      "Epoch 48 completed! | Train loss: 0.0021 | Train accuracy: 0.9995 | Validation loss: 0.1749 | Validation accuracy: 0.9667\n",
      "Epoch 49 completed! | Train loss: 0.0026 | Train accuracy: 0.9992 | Validation loss: 0.1852 | Validation accuracy: 0.9633\n",
      "Epoch 50 completed! | Train loss: 0.0131 | Train accuracy: 0.9956 | Validation loss: 0.3651 | Validation accuracy: 0.9367\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(28)\n",
    "torch.cuda.manual_seed(28)\n",
    "\n",
    "model_resnet = get_resnet(8)\n",
    "\n",
    "stats_resnet = train(\n",
    "    model_resnet, train_dataset, val_dataset, \n",
    "    batch_size=64, \n",
    "    loss_fn=nn.CrossEntropyLoss(), \n",
    "    optimizer=optim.Adam(model_resnet.parameters(), lr=0.001), \n",
    "    max_epochs=15,\n",
    "    save_name='architectures_resnet',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed! | Train loss: 2.0810 | Train accuracy: 0.1239 | Validation loss: 2.0793 | Validation accuracy: 0.1304\n",
      "Epoch 2 completed! | Train loss: 2.0805 | Train accuracy: 0.1217 | Validation loss: 2.0799 | Validation accuracy: 0.1275\n",
      "Epoch 3 completed! | Train loss: 2.0802 | Train accuracy: 0.1230 | Validation loss: 2.0803 | Validation accuracy: 0.1260\n",
      "Epoch 4 completed! | Train loss: 2.0804 | Train accuracy: 0.1228 | Validation loss: 2.0804 | Validation accuracy: 0.1193\n",
      "Epoch 5 completed! | Train loss: 2.0803 | Train accuracy: 0.1215 | Validation loss: 2.0805 | Validation accuracy: 0.1236\n",
      "Epoch 6 completed! | Train loss: 2.0805 | Train accuracy: 0.1206 | Validation loss: 2.0799 | Validation accuracy: 0.1260\n",
      "Epoch 7 completed! | Train loss: 2.0804 | Train accuracy: 0.1187 | Validation loss: 2.0793 | Validation accuracy: 0.1294\n",
      "Epoch 8 completed! | Train loss: 2.0804 | Train accuracy: 0.1232 | Validation loss: 2.0800 | Validation accuracy: 0.1255\n",
      "Epoch 9 completed! | Train loss: 2.0804 | Train accuracy: 0.1236 | Validation loss: 2.0802 | Validation accuracy: 0.1236\n",
      "Epoch 10 completed! | Train loss: 2.0806 | Train accuracy: 0.1216 | Validation loss: 2.0796 | Validation accuracy: 0.1304\n",
      "Epoch 11 completed! | Train loss: 2.0803 | Train accuracy: 0.1246 | Validation loss: 2.0794 | Validation accuracy: 0.1304\n",
      "Epoch 12 completed! | Train loss: 2.0801 | Train accuracy: 0.1212 | Validation loss: 2.0801 | Validation accuracy: 0.1241\n",
      "Epoch 13 completed! | Train loss: 2.0806 | Train accuracy: 0.1222 | Validation loss: 2.0799 | Validation accuracy: 0.1304\n",
      "Epoch 14 completed! | Train loss: 2.0805 | Train accuracy: 0.1254 | Validation loss: 2.0798 | Validation accuracy: 0.1304\n",
      "Epoch 15 completed! | Train loss: 2.0805 | Train accuracy: 0.1219 | Validation loss: 2.0793 | Validation accuracy: 0.1434\n",
      "Epoch 16 completed! | Train loss: 2.0803 | Train accuracy: 0.1250 | Validation loss: 2.0799 | Validation accuracy: 0.1255\n",
      "Epoch 17 completed! | Train loss: 2.0804 | Train accuracy: 0.1239 | Validation loss: 2.0799 | Validation accuracy: 0.1255\n",
      "Epoch 18 completed! | Train loss: 2.0805 | Train accuracy: 0.1243 | Validation loss: 2.0799 | Validation accuracy: 0.1260\n",
      "Epoch 19 completed! | Train loss: 2.0803 | Train accuracy: 0.1222 | Validation loss: 2.0797 | Validation accuracy: 0.1231\n",
      "Epoch 20 completed! | Train loss: 2.0802 | Train accuracy: 0.1224 | Validation loss: 2.0800 | Validation accuracy: 0.1236\n",
      "Epoch 21 completed! | Train loss: 2.0804 | Train accuracy: 0.1223 | Validation loss: 2.0802 | Validation accuracy: 0.1241\n",
      "Epoch 22 completed! | Train loss: 2.0803 | Train accuracy: 0.1190 | Validation loss: 2.0795 | Validation accuracy: 0.1255\n",
      "Epoch 23 completed! | Train loss: 2.0805 | Train accuracy: 0.1229 | Validation loss: 2.0796 | Validation accuracy: 0.1241\n",
      "Epoch 24 completed! | Train loss: 2.0801 | Train accuracy: 0.1244 | Validation loss: 2.0795 | Validation accuracy: 0.1275\n",
      "Epoch 25 completed! | Train loss: 2.0806 | Train accuracy: 0.1220 | Validation loss: 2.0801 | Validation accuracy: 0.1193\n",
      "Epoch 26 completed! | Train loss: 2.0805 | Train accuracy: 0.1194 | Validation loss: 2.0798 | Validation accuracy: 0.1038\n",
      "Epoch 27 completed! | Train loss: 2.0805 | Train accuracy: 0.1234 | Validation loss: 2.0795 | Validation accuracy: 0.1410\n",
      "Epoch 28 completed! | Train loss: 2.0803 | Train accuracy: 0.1206 | Validation loss: 2.0803 | Validation accuracy: 0.1193\n",
      "Epoch 29 completed! | Train loss: 2.0807 | Train accuracy: 0.1230 | Validation loss: 2.0799 | Validation accuracy: 0.1275\n",
      "Epoch 30 completed! | Train loss: 2.0805 | Train accuracy: 0.1241 | Validation loss: 2.0799 | Validation accuracy: 0.1260\n",
      "Epoch 31 completed! | Train loss: 2.0802 | Train accuracy: 0.1261 | Validation loss: 2.0803 | Validation accuracy: 0.1231\n",
      "Epoch 32 completed! | Train loss: 2.0803 | Train accuracy: 0.1241 | Validation loss: 2.0807 | Validation accuracy: 0.1236\n",
      "Epoch 33 completed! | Train loss: 2.0806 | Train accuracy: 0.1257 | Validation loss: 2.0800 | Validation accuracy: 0.1236\n",
      "Epoch 34 completed! | Train loss: 2.0805 | Train accuracy: 0.1160 | Validation loss: 2.0800 | Validation accuracy: 0.1241\n",
      "Epoch 35 completed! | Train loss: 2.0804 | Train accuracy: 0.1226 | Validation loss: 2.0803 | Validation accuracy: 0.1241\n",
      "Epoch 36 completed! | Train loss: 2.0806 | Train accuracy: 0.1209 | Validation loss: 2.0801 | Validation accuracy: 0.1410\n",
      "Epoch 37 completed! | Train loss: 2.0805 | Train accuracy: 0.1214 | Validation loss: 2.0801 | Validation accuracy: 0.1226\n",
      "Epoch 38 completed! | Train loss: 2.0806 | Train accuracy: 0.1155 | Validation loss: 2.0794 | Validation accuracy: 0.1482\n",
      "Epoch 39 completed! | Train loss: 2.0804 | Train accuracy: 0.1234 | Validation loss: 2.0800 | Validation accuracy: 0.1275\n",
      "Epoch 40 completed! | Train loss: 2.0805 | Train accuracy: 0.1266 | Validation loss: 2.0804 | Validation accuracy: 0.1193\n",
      "Epoch 41 completed! | Train loss: 2.0806 | Train accuracy: 0.1228 | Validation loss: 2.0795 | Validation accuracy: 0.1236\n",
      "Epoch 42 completed! | Train loss: 2.0802 | Train accuracy: 0.1238 | Validation loss: 2.0794 | Validation accuracy: 0.1241\n",
      "Epoch 43 completed! | Train loss: 2.0803 | Train accuracy: 0.1245 | Validation loss: 2.0804 | Validation accuracy: 0.1188\n",
      "Epoch 44 completed! | Train loss: 2.0802 | Train accuracy: 0.1244 | Validation loss: 2.0794 | Validation accuracy: 0.1275\n",
      "Epoch 45 completed! | Train loss: 2.0803 | Train accuracy: 0.1257 | Validation loss: 2.0795 | Validation accuracy: 0.1410\n",
      "Epoch 46 completed! | Train loss: 2.0804 | Train accuracy: 0.1260 | Validation loss: 2.0809 | Validation accuracy: 0.1241\n",
      "Epoch 47 completed! | Train loss: 2.0802 | Train accuracy: 0.1242 | Validation loss: 2.0794 | Validation accuracy: 0.1255\n",
      "Epoch 48 completed! | Train loss: 2.0803 | Train accuracy: 0.1180 | Validation loss: 2.0800 | Validation accuracy: 0.0995\n",
      "Epoch 49 completed! | Train loss: 2.0806 | Train accuracy: 0.1226 | Validation loss: 2.0794 | Validation accuracy: 0.1309\n",
      "Epoch 50 completed! | Train loss: 2.0802 | Train accuracy: 0.1248 | Validation loss: 2.0798 | Validation accuracy: 0.1241\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(28)\n",
    "torch.cuda.manual_seed(28)\n",
    "\n",
    "model_crnn = CustomCRNN(8)\n",
    "\n",
    "stats_crnn = train(\n",
    "    model_crnn, train_dataset, val_dataset, \n",
    "    batch_size=64, \n",
    "    loss_fn=nn.CrossEntropyLoss(), \n",
    "    optimizer=optim.Adam(model_crnn.parameters(), lr=0.001), \n",
    "    max_epochs=50,\n",
    "    save_name='architectures_crnn'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train vit base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed! | Train loss: 2.1413 | Train accuracy: 0.1267 | Validation loss: 2.0881 | Validation accuracy: 0.1304\n",
      "Epoch 2 completed! | Train loss: 2.0883 | Train accuracy: 0.1322 | Validation loss: 2.0689 | Validation accuracy: 0.1719\n",
      "Epoch 3 completed! | Train loss: 2.0864 | Train accuracy: 0.1346 | Validation loss: 2.0833 | Validation accuracy: 0.1193\n",
      "Epoch 4 completed! | Train loss: 2.0940 | Train accuracy: 0.1302 | Validation loss: 2.0834 | Validation accuracy: 0.1193\n",
      "Epoch 5 completed! | Train loss: 2.0859 | Train accuracy: 0.1253 | Validation loss: 2.0825 | Validation accuracy: 0.1236\n",
      "Epoch 6 completed! | Train loss: 2.0852 | Train accuracy: 0.1267 | Validation loss: 2.0789 | Validation accuracy: 0.1275\n",
      "Epoch 7 completed! | Train loss: 2.0753 | Train accuracy: 0.1489 | Validation loss: 2.1031 | Validation accuracy: 0.1304\n",
      "Epoch 8 completed! | Train loss: 2.0848 | Train accuracy: 0.1233 | Validation loss: 2.0850 | Validation accuracy: 0.1241\n",
      "Epoch 9 completed! | Train loss: 2.0787 | Train accuracy: 0.1346 | Validation loss: 2.0809 | Validation accuracy: 0.1265\n",
      "Epoch 10 completed! | Train loss: 2.0334 | Train accuracy: 0.1819 | Validation loss: 2.0121 | Validation accuracy: 0.1931\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(28)\n",
    "torch.cuda.manual_seed(28)\n",
    "\n",
    "vit_base = get_vit_base()\n",
    "\n",
    "stats_vit_base = train(\n",
    "    vit_base, train_dataset, val_dataset, \n",
    "    batch_size=32, \n",
    "    loss_fn=nn.CrossEntropyLoss(), \n",
    "    optimizer=optim.Adam(vit_base.parameters(), lr=0.001), \n",
    "    max_epochs=10,\n",
    "    save_name='architectures_vit_base',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train vit large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed! | Train loss: 2.1366 | Train accuracy: 0.1272 | Validation loss: 2.0833 | Validation accuracy: 0.1241\n",
      "Epoch 2 completed! | Train loss: 2.0935 | Train accuracy: 0.1273 | Validation loss: 2.0929 | Validation accuracy: 0.1236\n",
      "Epoch 3 completed! | Train loss: 2.0914 | Train accuracy: 0.1246 | Validation loss: 2.0835 | Validation accuracy: 0.1260\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m28\u001b[39m)\n\u001b[0;32m      4\u001b[0m vit_large \u001b[38;5;241m=\u001b[39m get_vit_large()\n\u001b[1;32m----> 6\u001b[0m stats_vit_base \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvit_large\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvit_large\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marchitectures_vit_large\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 43\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(network, train_dataset, valid_dataset, batch_size, loss_fn, optimizer, max_epochs, save_name, verbosity_period)\u001b[0m\n\u001b[0;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# update current epoch's stats\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m train_epoch_loss_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# calculate accuracy but only if no advanced augmentations are used\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# this is because with advanced augmentations true_labels becomes\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# probabilites of each class\u001b[39;00m\n\u001b[0;32m     47\u001b[0m pred_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(pred_proba, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(28)\n",
    "torch.cuda.manual_seed(28)\n",
    "\n",
    "vit_large = get_vit_large()\n",
    "\n",
    "stats_vit_base = train(\n",
    "    vit_large, train_dataset, val_dataset, \n",
    "    batch_size=16, \n",
    "    loss_fn=nn.CrossEntropyLoss(), \n",
    "    optimizer=optim.Adam(vit_large.parameters(), lr=0.001), \n",
    "    max_epochs=5,\n",
    "    save_name='architectures_vit_large',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bayes_result(path: str, best_params: dict[str, Any], best_accuracy: float):\n",
    "    data = {\n",
    "        'best_params': best_params,\n",
    "        'best_accuracy': best_accuracy,\n",
    "    }\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, 'w') as file:\n",
    "        json.dump(data, file)\n",
    "\n",
    "\n",
    "def load_bayes_result(path: str) -> tuple[dict[str, Any], float]:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data['best_params'], data['best_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_resnet_adam(batch_size_exp, learning_rate, l2_reg, beta1, beta2):\n",
    "    batch_size = 2**int(batch_size_exp)\n",
    "    model = get_resnet(2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_reg, betas=(beta1, beta2))\n",
    "\n",
    "    stats = train(model, train_dataset, val_dataset, batch_size, criterion, optimizer, max_epochs=15, verbosity_period=0)\n",
    "    val_acc = stats['valid_accuracy'][-1]\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... |   beta1   |   beta2   |  l2_reg   | learni... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.873    \u001b[0m | \u001b[0m0.9412   \u001b[0m | \u001b[0m0.7247   \u001b[0m | \u001b[0m0.005991 \u001b[0m | \u001b[0m0.001645 \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m5.78     \u001b[0m | \u001b[0m0.0575   \u001b[0m | \u001b[0m0.8575   \u001b[0m | \u001b[0m0.006015 \u001b[0m | \u001b[0m0.00711  \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m9.975    \u001b[0m | \u001b[0m0.9284   \u001b[0m | \u001b[0m0.004239 \u001b[0m | \u001b[0m0.008856 \u001b[0m | \u001b[0m0.0007583\u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m0.1352   \u001b[0m | \u001b[0m0.0367   \u001b[0m | \u001b[0m0.001638 \u001b[0m | \u001b[0m0.007109 \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "pbounds = {\n",
    "    'batch_size_exp': (5, 10),  # will be rounded down so from 5 to 9, making batch size from 32 to 512\n",
    "    'learning_rate': (1e-4, 0.01),\n",
    "    'l2_reg': (1e-5, 0.01),\n",
    "    'beta1': (0.0, 0.99),\n",
    "    'beta2': (0.0, 0.99)\n",
    "    \n",
    "}\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective_function_resnet_adam,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42\n",
    ")\n",
    "optimizer.maximize(\n",
    "    init_points=2,\n",
    "    n_iter=2\n",
    ")\n",
    "best_hyperparams_resnet_adam = optimizer.max['params']\n",
    "accuracy_resnet_adam = optimizer.max['target']\n",
    "save_bayes_result('./saved/bayes/resnet_adam.json', best_hyperparams_resnet_adam, accuracy_resnet_adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_customcrnn_adam(batch_size_exp, learning_rate, l2_reg, beta1, beta2):\n",
    "    batch_size = 2**int(batch_size_exp)\n",
    "    model = CustomCRNN(8)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_reg, betas=(beta1, beta2))\n",
    "\n",
    "    stats = train(model, train_dataset, val_dataset, batch_size, criterion, optimizer, max_epochs=15, verbosity_period=0)\n",
    "    val_acc = stats['valid_accuracy'][-1]\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... |   beta1   |   beta2   |  l2_reg   | learni... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.873    \u001b[0m | \u001b[0m0.9412   \u001b[0m | \u001b[0m0.7247   \u001b[0m | \u001b[0m0.005991 \u001b[0m | \u001b[0m0.001645 \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1e-05    \u001b[0m | \u001b[0m0.01     \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m5.009    \u001b[0m | \u001b[0m0.9304   \u001b[0m | \u001b[0m0.9388   \u001b[0m | \u001b[0m0.007107 \u001b[0m | \u001b[0m0.00429  \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "pbounds = {\n",
    "    'batch_size_exp': (5, 10),  # will be rounded down so from 5 to 9, making batch size from 32 to 512\n",
    "    'learning_rate': (1e-4, 0.01),\n",
    "    'l2_reg': (1e-5, 0.01),\n",
    "    'beta1': (0.0, 0.99),\n",
    "    'beta2': (0.0, 0.99)\n",
    "}\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective_function_customcrnn_adam,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42\n",
    ")\n",
    "optimizer.maximize(\n",
    "    init_points=1,\n",
    "    n_iter=2\n",
    ")\n",
    "best_hyperparams_customcrnn = optimizer.max['params']\n",
    "accuracy_customcrnn = optimizer.max['target']\n",
    "save_bayes_result('./saved/bayes/customcrnn_adam.json', best_hyperparams_customcrnn, accuracy_customcrnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer VIT-base-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_vit_base_adam(batch_size_exp, learning_rate, l2_reg, beta1, beta2):\n",
    "    batch_size = 2**int(batch_size_exp)\n",
    "    model = get_vit_base()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_reg, betas=(beta1, beta2))\n",
    "\n",
    "    stats = train(model, train_dataset, val_dataset, batch_size, criterion, optimizer, max_epochs=15, verbosity_period=0)\n",
    "    val_acc = stats['valid_accuracy'][-1]\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... |   beta1   |   beta2   |  l2_reg   | learni... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m6.873    \u001b[0m | \u001b[0m0.9412   \u001b[0m | \u001b[0m0.7247   \u001b[0m | \u001b[0m0.005991 \u001b[0m | \u001b[0m0.001645 \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1e-05    \u001b[0m | \u001b[0m0.01     \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m5.009    \u001b[0m | \u001b[0m0.9304   \u001b[0m | \u001b[0m0.9388   \u001b[0m | \u001b[0m0.007107 \u001b[0m | \u001b[0m0.00429  \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "pbounds = {\n",
    "    'batch_size_exp': (5, 10),  # will be rounded down so from 5 to 9, making batch size from 32 to 512\n",
    "    'learning_rate': (1e-4, 0.01),\n",
    "    'l2_reg': (1e-5, 0.01),\n",
    "    'beta1': (0.0, 0.99),\n",
    "    'beta2': (0.0, 0.99)\n",
    "    \n",
    "}\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective_function_vit_base_adam,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42\n",
    ")\n",
    "optimizer.maximize(\n",
    "    init_points=1,\n",
    "    n_iter=2\n",
    ")\n",
    "best_hyperparams_vit_base_adam = optimizer.max['params']\n",
    "accuracy_vit_base_adam = optimizer.max['target']\n",
    "save_bayes_result('./saved/bayes/vit_base_adam.json', best_hyperparams_vit_base_adam, accuracy_vit_base_adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer VIT-large-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_vit_large_adam(batch_size_exp, learning_rate, l2_reg, beta1, beta2):\n",
    "    batch_size = 2**int(batch_size_exp)\n",
    "    model = get_vit_large()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_reg, betas=(beta1, beta2))\n",
    "\n",
    "    stats = train(model, train_dataset, val_dataset, batch_size, criterion, optimizer, max_epochs=15, verbosity_period=0)\n",
    "    val_acc = stats['valid_accuracy'][-1]\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = {\n",
    "    'batch_size_exp': (5, 10),  # will be rounded down so from 5 to 9, making batch size from 32 to 512\n",
    "    'learning_rate': (1e-4, 0.01),\n",
    "    'l2_reg': (1e-5, 0.01),\n",
    "    'beta1': (0.0, 0.99),\n",
    "    'beta2': (0.0, 0.99)\n",
    "    \n",
    "}\n",
    "optimizer = BayesianOptimization(\n",
    "    f=objective_function_vit_large_adam,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42\n",
    ")\n",
    "optimizer.maximize(\n",
    "    init_points=0,\n",
    "    n_iter=1\n",
    ")\n",
    "best_hyperparams_vit_large_adam = optimizer.max['params']\n",
    "accuracy_vit_large_adam = optimizer.max['target']\n",
    "save_bayes_result('./saved/bayes/vit_large_adam.json', best_hyperparams_vit_large_adam, accuracy_vit_large_adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "def calculate_confusion_matrix(predictor: nn.Module, dataset: torch.Tensor, n_classes: int, verbose=True):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        Confusion matrix, total accuracy, accuracy per class\n",
    "    \"\"\"\n",
    "    batch_size = 1000\n",
    "    photos_processed = 0\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    predictor.eval()\n",
    "\n",
    "    confusion_matrix = torch.zeros(n_classes, n_classes)\n",
    "    true_counts_per_class = torch.zeros(n_classes)\n",
    "    class_counts = torch.zeros(n_classes)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, true_labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            true_labels = true_labels.to(device)\n",
    "            pred = predictor(images)\n",
    "            if len(pred.shape) == 2:\n",
    "                pred = torch.argmax(pred, dim=1)\n",
    "\n",
    "            for true_label, pred_label in zip(true_labels, pred):\n",
    "                confusion_matrix[true_label, pred_label] += 1\n",
    "                class_counts[true_label] += 1\n",
    "                if true_label == pred_label:\n",
    "                    true_counts_per_class[true_label] += 1\n",
    "\n",
    "            if verbose:\n",
    "                photos_processed += batch_size\n",
    "                print(f'processed {photos_processed} photos')\n",
    "\n",
    "    accuracy_per_class = (true_counts_per_class / class_counts).tolist()\n",
    "    accuracy_total = float(true_counts_per_class.sum() / class_counts.sum())\n",
    "\n",
    "    return confusion_matrix, accuracy_total, accuracy_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_resnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m matrix_resnet, acc_total_resnet, acc_per_class_resnet \u001b[38;5;241m=\u001b[39m calculate_confusion_matrix(\u001b[43mmodel_resnet\u001b[49m, train_dataset, n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_resnet' is not defined"
     ]
    }
   ],
   "source": [
    "matrix_resnet, acc_total_resnet, acc_per_class_resnet = calculate_confusion_matrix(model_resnet, train_dataset, n_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_crnn, acc_total_crnn, acc_per_class_crnn = calculate_confusion_matrix(model_crnn, train_dataset, n_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1000 photos\n"
     ]
    }
   ],
   "source": [
    "matrix_vit_base, acc_total_vit_base, acc_per_class_vit_base = calculate_confusion_matrix(vit_base, train_dataset, n_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_vit_large, acc_total_vit_large, acc_per_class_vit_large = calculate_confusion_matrix(vit_large, train_dataset, n_classes=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silence and Unknown detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
