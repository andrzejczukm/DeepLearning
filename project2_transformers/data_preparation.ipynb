{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "129fe840",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "https://www.kaggle.com/competitions/tensorflow-speech-recognition-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22bc5599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import librosa\n",
    "from librosa.feature import melspectrogram\n",
    "from librosa.display import specshow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b6e1474",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_base_path = 'data/raw'\n",
    "audio_base_path = f'{raw_data_base_path}/audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d472340",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{raw_data_base_path}/validation_list.txt', 'r') as file:\n",
    "    validation_list = file.readlines()\n",
    "    validation_list = {path.strip() for path in validation_list}\n",
    "\n",
    "with open(f'{raw_data_base_path}/testing_list.txt', 'r') as file:\n",
    "    testing_list = file.readlines()\n",
    "    testing_list = {path.strip() for path in testing_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d3c22f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mel_spectogram(signal, sample_rate, folder: str, name: str):\n",
    "    \"\"\"\n",
    "    name - np. \"bed/00f0204f_nohash_0.wav\"\n",
    "    \"\"\"\n",
    "    mel_spectrogram = melspectrogram(y=signal, sr=sample_rate)\n",
    "    mel_spectrogram_abs = np.abs(mel_spectrogram)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram_abs, ref=np.max)\n",
    "\n",
    "    fig = plt.Figure(figsize=(8, 7))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    specshow(\n",
    "        mel_spectrogram_db, sr=sample_rate, x_axis='time', y_axis='mel',\n",
    "        cmap='magma', ax=ax,\n",
    "    )\n",
    "    ax.axis('off')\n",
    "\n",
    "    save_path = f'data/processed/{folder}/{name[:-4]}.png'\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    fig.savefig(save_path, pad_inches=-0.1, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b36f903",
   "metadata": {},
   "source": [
    "# Generate mel-spectrograms for known classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53593b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['train', 'valid', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9917bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_known = ['up', 'down', 'left', 'right', 'on', 'off', 'yes', 'no']\n",
    "# number of observations in all known classes combined (train/valid/test)\n",
    "known_counts = [0, 0, 0]\n",
    "\n",
    "for label in folders_known:\n",
    "    print(f'Processing {label} class...')\n",
    "    for filename in os.listdir(f'{audio_base_path}/{label}'):\n",
    "        \n",
    "        full_name = f'{label}/{filename}'\n",
    "        full_silence_signal, sample_rate = librosa.load(f'{audio_base_path}/{full_name}')\n",
    "\n",
    "        # check which subset\n",
    "        if full_name in validation_list:\n",
    "            dataset_id = 1\n",
    "        elif full_name in testing_list:\n",
    "            dataset_id = 2\n",
    "        else:\n",
    "            dataset_id = 0\n",
    "\n",
    "        folder = datasets[dataset_id]\n",
    "        known_counts[dataset_id] += 1\n",
    "\n",
    "        generate_mel_spectogram(full_silence_signal, sample_rate, f'{folder}/known', full_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a33ce8d",
   "metadata": {},
   "source": [
    "# Generate mel-spectrograms for unknown class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29a4385a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14792, 2071, 2067]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "057adc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_classes_count = 30 - len(folders_known)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2871cc",
   "metadata": {},
   "source": [
    "We want to create a varied unknown class, so we take the same number of samples from each unknown class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a6c6b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[672, 94, 93]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_size_per_class = [c // unknown_classes_count for c in known_counts]\n",
    "subset_size_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40abe324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing marvin class...\n",
      "Processing six class...\n",
      "Processing sheila class...\n",
      "Processing four class...\n",
      "Processing go class...\n",
      "Processing stop class...\n",
      "Processing five class...\n",
      "Processing seven class...\n",
      "Processing bird class...\n",
      "Processing bed class...\n",
      "Processing nine class...\n",
      "Processing two class...\n",
      "Processing dog class...\n",
      "Processing happy class...\n",
      "Processing tree class...\n",
      "Processing eight class...\n",
      "Processing cat class...\n",
      "Processing wow class...\n",
      "Processing house class...\n",
      "Processing three class...\n",
      "Processing zero class...\n",
      "Processing one class...\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(28)\n",
    "\n",
    "for label in os.listdir(audio_base_path):\n",
    "    if label in folders_known or label == '_background_noise_':\n",
    "        continue\n",
    "\n",
    "    path = f'{audio_base_path}/{label}'\n",
    "    if not os.path.isdir(path):\n",
    "        continue\n",
    "\n",
    "    files = os.listdir(f'{audio_base_path}/{label}')\n",
    "    # randomise files order\n",
    "    rng.shuffle(files)\n",
    "    # track the number of files we processed for this class\n",
    "    curr_counts = [0, 0, 0]\n",
    "\n",
    "    print(f'Processing {label} class...')\n",
    "    for filename in files:\n",
    "        \n",
    "        full_name = f'{label}/{filename}'\n",
    "        full_silence_signal, sample_rate = librosa.load(f'{audio_base_path}/{full_name}')\n",
    "\n",
    "        # check which subset\n",
    "        if full_name in validation_list:\n",
    "            dataset_id = 1\n",
    "        elif full_name in testing_list:\n",
    "            dataset_id = 2\n",
    "        else:\n",
    "            dataset_id = 0\n",
    "\n",
    "        # if we have enough of this class in this dataset then move on to the next file\n",
    "        if curr_counts[dataset_id] == subset_size_per_class[dataset_id]:\n",
    "            continue \n",
    "\n",
    "        folder = datasets[dataset_id]\n",
    "        curr_counts[dataset_id] += 1\n",
    "        # here we merge class label with the filename\n",
    "        generate_mel_spectogram(full_silence_signal, sample_rate, f'{folder}/unknown', full_name.replace('/', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca3778",
   "metadata": {},
   "source": [
    "# Generate mel-spectrogramns for silence class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c1d06a",
   "metadata": {},
   "source": [
    "We want silence files to have the same length as the other files. If a piece of audio at the end of the file is too short, in order to standardize the audio data, we will extend it with silence to ensure all files have equal duration of sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6df41f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, _ = librosa.load(f'{audio_base_path}/bed/00f0204f_nohash_0.wav')\n",
    "audio_len = len(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b001ffa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10940306391970417"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_frac = known_counts[1] / np.sum(known_counts)\n",
    "valid_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2c28c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, valid, test\n",
    "silence_signals = [[], [], []]\n",
    "bg_noise_path = f'{audio_base_path}/_background_noise_'\n",
    "\n",
    "rng = np.random.default_rng(26)\n",
    "\n",
    "for filename in os.listdir(bg_noise_path):\n",
    "    if not filename.endswith('.wav'):\n",
    "        continue\n",
    "\n",
    "    full_silence_signal, sample_rate = librosa.load(f'{bg_noise_path}/{filename}')\n",
    "    silence_segments = []\n",
    "    for boundary in range(0, len(full_silence_signal), audio_len):\n",
    "        silence = full_silence_signal[boundary:boundary + audio_len]\n",
    "        \n",
    "        silence_len = len(silence)\n",
    "        if silence_len < audio_len:\n",
    "            # fill with 0s\n",
    "            silence = np.pad(silence, (0, audio_len - silence_len), mode='constant')\n",
    "        \n",
    "        silence_segments.append(silence)\n",
    "    # add new samples to the respective datasets\n",
    "    rng.shuffle(silence_segments)\n",
    "    valid_size = int(valid_frac * len(silence_segments))\n",
    "    # valid\n",
    "    silence_signals[1].extend(silence_segments[:valid_size])\n",
    "    # test\n",
    "    silence_signals[2].extend(silence_segments[valid_size:2*valid_size])\n",
    "    # train\n",
    "    silence_signals[0].extend(silence_segments[2*valid_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5102c32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[322, 40, 40]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(s) for s in silence_signals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "58eafc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14792, 2071, 2067]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6d6102",
   "metadata": {},
   "source": [
    "# Generate a small subset of data for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a5e20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbea959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subset(size: int):\n",
    "    for label in ['yes', 'no']:\n",
    "        for dataset in datasets:\n",
    "            processed = f'data/processed/{dataset}/known/{label}'\n",
    "            subset = f'data/subset/{dataset}/known/{label}'\n",
    "            os.makedirs(subset, exist_ok=True)\n",
    "            n_files = 0\n",
    "            for filename in os.listdir(processed):\n",
    "                shutil.copy(f'{processed}/{filename}', f'{subset}/{filename}')\n",
    "                n_files += 1\n",
    "                if n_files == size:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d7ee019",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_subset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a8d538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
