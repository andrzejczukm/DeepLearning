{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "129fe840",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "https://www.kaggle.com/competitions/tensorflow-speech-recognition-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22bc5599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import librosa\n",
    "from librosa.feature import melspectrogram\n",
    "from librosa.display import specshow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89001de5",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee72be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_known = ['up', 'down', 'left', 'right', 'on', 'off', 'yes', 'no']\n",
    "\n",
    "# uncomment below line for less 'known' classes\n",
    "# classes_known = ['yes', 'no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b6e1474",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_base_path = 'data/raw'\n",
    "audio_base_path = f'{raw_data_base_path}/audio'\n",
    "out_dir = f'data/processed{len(classes_known)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d472340",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{raw_data_base_path}/validation_list.txt', 'r') as file:\n",
    "    validation_list = file.readlines()\n",
    "    validation_list = {path.strip() for path in validation_list}\n",
    "\n",
    "with open(f'{raw_data_base_path}/testing_list.txt', 'r') as file:\n",
    "    testing_list = file.readlines()\n",
    "    testing_list = {path.strip() for path in testing_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3c22f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mel_spectogram(signal, sample_rate, folder: str, name: str):\n",
    "    \"\"\"\n",
    "    name - np. \"bed/00f0204f_nohash_0.wav\"\n",
    "    \"\"\"\n",
    "    mel_spectrogram = melspectrogram(y=signal, sr=sample_rate, hop_length=160)\n",
    "    mel_spectrogram_abs = np.abs(mel_spectrogram)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram_abs, ref=np.max)\n",
    "    # flip so that low frequencies are at the bottom\n",
    "    mel_spectrogram_db_flipped = np.flip(mel_spectrogram_db, axis=0)\n",
    "\n",
    "    save_path = f'{out_dir}/{folder}/{name[:-4]}.png'\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    plt.imsave(save_path, mel_spectrogram_db_flipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b36f903",
   "metadata": {},
   "source": [
    "# Generate mel-spectrograms for known classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53593b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['train', 'valid', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9917bc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing \"up\" class...\n",
      "Processing \"down\" class...\n",
      "Processing \"left\" class...\n",
      "Processing \"right\" class...\n",
      "Processing \"on\" class...\n",
      "Processing \"off\" class...\n",
      "Processing \"yes\" class...\n",
      "Processing \"no\" class...\n"
     ]
    }
   ],
   "source": [
    "# number of observations in all known classes combined (train/valid/test)\n",
    "known_counts = [0, 0, 0]\n",
    "\n",
    "for label in classes_known:\n",
    "    print(f'Processing \"{label}\" class...')\n",
    "    for filename in os.listdir(f'{audio_base_path}/{label}'):\n",
    "        \n",
    "        full_name = f'{label}/{filename}'\n",
    "        signal, sample_rate = librosa.load(f'{audio_base_path}/{full_name}')\n",
    "\n",
    "        # check which subset\n",
    "        if full_name in validation_list:\n",
    "            dataset_id = 1\n",
    "        elif full_name in testing_list:\n",
    "            dataset_id = 2\n",
    "        else:\n",
    "            dataset_id = 0\n",
    "\n",
    "        folder = datasets[dataset_id]\n",
    "        known_counts[dataset_id] += 1\n",
    "\n",
    "        generate_mel_spectogram(signal, sample_rate, folder, full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b147049a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1849, 258, 258]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_class_count = [int(value / len(classes_known)) for value in known_counts]\n",
    "single_class_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3550d11",
   "metadata": {},
   "source": [
    "# Generate mel-spectrogramns for silence class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c1d06a",
   "metadata": {},
   "source": [
    "We want silence files to have the same length as the other files. If a piece of audio at the end of the file is too short, in order to standardize the audio data, we will extend it with silence to ensure all files have equal duration of sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6df41f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, _ = librosa.load(f'{audio_base_path}/bed/00f0204f_nohash_0.wav')\n",
    "audio_len = len(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b001ffa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10909090909090909"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_frac = single_class_count[1] / np.sum(single_class_count)\n",
    "valid_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c28c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, valid, test\n",
    "silence_signals = [[], [], []]\n",
    "bg_noise_path = f'{audio_base_path}/_background_noise_'\n",
    "\n",
    "rng = np.random.default_rng(26)\n",
    "\n",
    "for filename in os.listdir(bg_noise_path):\n",
    "    if not filename.endswith('.wav'):\n",
    "        continue\n",
    "\n",
    "    full_silence_signal, sample_rate = librosa.load(f'{bg_noise_path}/{filename}')\n",
    "    silence_segments = []\n",
    "    # split into segments\n",
    "    for boundary in range(0, len(full_silence_signal), audio_len):\n",
    "        silence = full_silence_signal[boundary:boundary + audio_len]\n",
    "        \n",
    "        silence_len = len(silence)\n",
    "        if silence_len < audio_len:\n",
    "            # fill with 0s\n",
    "            silence = np.pad(silence, (0, audio_len - silence_len), mode='constant')\n",
    "        \n",
    "        silence_segments.append(silence)\n",
    "        \n",
    "    # add new samples to the respective datasets\n",
    "    rng.shuffle(silence_segments)\n",
    "    valid_size = int(np.round(valid_frac * len(silence_segments)))\n",
    "    # valid\n",
    "    silence_signals[1].extend(silence_segments[:valid_size])\n",
    "    # test\n",
    "    silence_signals[2].extend(silence_segments[valid_size:2*valid_size])\n",
    "    # train\n",
    "    silence_signals[0].extend(silence_segments[2*valid_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8e2e54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, valid, test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[312, 45, 45]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train, valid, test')\n",
    "[len(s) for s in silence_signals]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef04849",
   "metadata": {},
   "source": [
    "There are very little samples in the *silence* class compared to the other two classes. Below we generate additional samples in the following way:\n",
    "\n",
    "1. Add reversed versions of each signal to the dataset\n",
    "2. Make multiple copies of each signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e044104a",
   "metadata": {},
   "source": [
    "### 1. Add reversed versions of each signal to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "325391b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for silence_dataset in silence_signals:\n",
    "    for i in range(len(silence_dataset)):\n",
    "        signal_original = silence_dataset[i]\n",
    "        signal_reversed = np.flip(signal_original)\n",
    "        silence_dataset.append(signal_reversed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bba870d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, valid, test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[624, 90, 90]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train, valid, test')\n",
    "silence_count = [len(s) for s in silence_signals]\n",
    "silence_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d225304",
   "metadata": {},
   "source": [
    "### Generate spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca941cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name, silence_dataset in zip(datasets, silence_signals):\n",
    "    for i, signal in enumerate(silence_dataset):\n",
    "        generate_mel_spectogram(signal, sample_rate, f'{dataset_name}/other/silence', f'{i}.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5654407f",
   "metadata": {},
   "source": [
    "# Generate mel-spectrograms for unknown class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "314c6153",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_class_count = [value1 - value2 for value1, value2 in zip(single_class_count, silence_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfe261f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_classes_count = 30 - len(classes_known)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7def013c",
   "metadata": {},
   "source": [
    "We want to create a varied unknown class, so we take the same number of samples from each unknown class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce80c812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55, 7, 7]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_size_per_class = [c // unknown_classes_count for c in unknown_class_count]\n",
    "subset_size_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e83e3fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing \"bed\" class...\n",
      "Processing \"bird\" class...\n",
      "Processing \"cat\" class...\n",
      "Processing \"dog\" class...\n",
      "Processing \"eight\" class...\n",
      "Processing \"five\" class...\n",
      "Processing \"four\" class...\n",
      "Processing \"go\" class...\n",
      "Processing \"happy\" class...\n",
      "Processing \"house\" class...\n",
      "Processing \"marvin\" class...\n",
      "Processing \"nine\" class...\n",
      "Processing \"one\" class...\n",
      "Processing \"seven\" class...\n",
      "Processing \"sheila\" class...\n",
      "Processing \"six\" class...\n",
      "Processing \"stop\" class...\n",
      "Processing \"three\" class...\n",
      "Processing \"tree\" class...\n",
      "Processing \"two\" class...\n",
      "Processing \"wow\" class...\n",
      "Processing \"zero\" class...\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(28)\n",
    "\n",
    "for label in os.listdir(audio_base_path):\n",
    "    if label in classes_known or label == '_background_noise_':\n",
    "        continue\n",
    "\n",
    "    path = f'{audio_base_path}/{label}'\n",
    "    if not os.path.isdir(path):\n",
    "        continue\n",
    "\n",
    "    files = os.listdir(f'{audio_base_path}/{label}')\n",
    "    # randomise files order\n",
    "    rng.shuffle(files)\n",
    "    # track the number of files we processed for this class\n",
    "    curr_counts = [0, 0, 0]\n",
    "\n",
    "    print(f'Processing \"{label}\" class...')\n",
    "    for filename in files:\n",
    "        \n",
    "        full_name = f'{label}/{filename}'\n",
    "        signal, sample_rate = librosa.load(f'{audio_base_path}/{full_name}')\n",
    "\n",
    "        # check which subset\n",
    "        if full_name in validation_list:\n",
    "            dataset_id = 1\n",
    "        elif full_name in testing_list:\n",
    "            dataset_id = 2\n",
    "        else:\n",
    "            dataset_id = 0\n",
    "\n",
    "        # if we have enough of this class in this dataset then move on to the next file\n",
    "        if curr_counts[dataset_id] == subset_size_per_class[dataset_id]:\n",
    "            continue \n",
    "\n",
    "        folder = datasets[dataset_id]\n",
    "        curr_counts[dataset_id] += 1\n",
    "        # here we merge class label with the filename\n",
    "        generate_mel_spectogram(signal, sample_rate, f'{folder}/other/unknown', full_name.replace('/', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6d6102",
   "metadata": {},
   "source": [
    "# Generate a small subset of data for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44977112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbea959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subset(size: int):\n",
    "    for label in ['yes', 'no', 'other/unknown', 'other/silence']:\n",
    "        for dataset in datasets:\n",
    "            processed = f'{out_dir}/{dataset}/{label}'\n",
    "            subset = f'data/subset/{dataset}/{label}'\n",
    "            os.makedirs(subset, exist_ok=True)\n",
    "            n_files = 0\n",
    "            for filename in os.listdir(processed):\n",
    "                shutil.copy(f'{processed}/{filename}', f'{subset}/{filename}')\n",
    "                n_files += 1\n",
    "                if n_files == size:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d7ee019",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_subset(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
