{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "https://www.kaggle.com/datasets/jhoward/lsun_bedroom/data\n",
    "\n",
    "@misc{yu2016lsun,\n",
    "      title={LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop}, \n",
    "      author={Fisher Yu and Ari Seff and Yinda Zhang and Shuran Song and Thomas Funkhouser and Jianxiong Xiao},\n",
    "      year={2016},\n",
    "      eprint={1506.03365},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.CV}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = './data/subset'\n",
    "data_path = './data/data0/lsun/bedroom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size after transformations\n",
    "image_size = 64\n",
    "\n",
    "simple_load = v2.Compose([\n",
    "    v2.Resize((image_size, image_size)),\n",
    "    v2.PILToTensor(),\n",
    "    v2.ToDtype(torch.float32),\n",
    "    v2.Normalize([0.5], [0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDPM\n",
    "\n",
    "https://huggingface.co/docs/diffusers/en/tutorials/basic_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMPipeline, DDPMScheduler, UNet2DModel\n",
    "from diffusers.utils import make_image_grid\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3270e410910345c49b7aa2ce884f3dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/303125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(data_path, split='train')\n",
    "dataset.set_transform(simple_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = UNet2DModel(\n",
    "    sample_size=image_size,  # the target image resolution\n",
    "    in_channels=3,  # the number of input channels, 3 for RGB images\n",
    "    out_channels=3,  # the number of output channels\n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),  # the number of output channels for each UNet block\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "        \"DownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",  # a regular ResNet upsampling block\n",
    "        \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(epoch, pipeline, save_name: str = 'ddpm_training', random_state: int | None = None):\n",
    "    # Sample some images from random noise (this is the backward diffusion process).\n",
    "    # The default pipeline output type is `List[PIL.Image]`\n",
    "    images = pipeline(\n",
    "        batch_size=16,\n",
    "        generator=torch.manual_seed(random_state),\n",
    "    ).images\n",
    "\n",
    "    # Make a grid out of the images\n",
    "    image_grid = make_image_grid(images, rows=4, cols=4)\n",
    "\n",
    "    # Save the images\n",
    "    test_dir = os.path.join('saved', save_name)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    image_grid.save(f\"{test_dir}/{epoch:04d}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unet(model, n_epochs: int, noise_scheduler, optimizer, dataset, batch_size: int = 16, start_epoch: int = 0,\n",
    "               save_every: int = 1, save_name: str = 'ddpm_training'):\n",
    "    data_loader = DataLoader(dataset, batch_size)\n",
    "\n",
    "    for i in range(start_epoch, n_epochs + start_epoch):\n",
    "        epoch_no = i + 1\n",
    "        print(f'Starting epoch {epoch_no}...')\n",
    "\n",
    "        for batch in tqdm(data_loader):\n",
    "\n",
    "            # move to cuda/cpu\n",
    "            clean_images = batch[\"image\"].to(device)\n",
    "\n",
    "            # Sample noise to add to the images\n",
    "            noise = torch.randn(clean_images.shape, device=device)\n",
    "            bs = clean_images.shape[0]\n",
    "\n",
    "            # Sample a random timestep for each image\n",
    "            timesteps = torch.randint(\n",
    "                0, noise_scheduler.config.num_train_timesteps, (bs,), device=device,\n",
    "                dtype=torch.int64\n",
    "            )\n",
    "\n",
    "            # Add noise to the clean images according to the noise magnitude at each timestep\n",
    "            # (this is the forward diffusion process)\n",
    "            noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
    "\n",
    "            # Predict the noise residual\n",
    "            noise_pred = model(noisy_images, timesteps, return_dict=False)[0]\n",
    "            loss = F.mse_loss(noise_pred, noise)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # evaluate every nth epoch\n",
    "        if epoch_no % save_every == 0:\n",
    "            print(f'Evaluating after epoch {epoch_no}...')\n",
    "            # save model\n",
    "            save_dir = f'saved/{save_name}'\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            model.save_pretrained(f'{save_dir}/{epoch_no:04d}_model')\n",
    "            # evaluate and save images\n",
    "            pipeline = DDPMPipeline(unet=model, scheduler=noise_scheduler)\n",
    "            evaluate(epoch_no, pipeline, save_name, random_state=epoch_no)\n",
    "        \n",
    "        # cooldown\n",
    "        time.sleep(60 * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing learning rate $10^{-3}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unet(\n",
    "    unet_model, \n",
    "    n_epochs=5, \n",
    "    noise_scheduler=noise_scheduler, \n",
    "    optimizer=optim.Adam(unet_model.parameters()), # default lr = 0.001\n",
    "    dataset=dataset, \n",
    "    batch_size=16,\n",
    "    save_every=1,\n",
    "    save_name='ddpm_training_lr1e-3',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing learning rate $10^{-4}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 84/18946 [00:44<2:46:44,  1.89it/s]"
     ]
    }
   ],
   "source": [
    "train_unet(\n",
    "    unet_model, \n",
    "    n_epochs=20, \n",
    "    noise_scheduler=noise_scheduler, \n",
    "    optimizer=optim.Adam(unet_model.parameters(), lr=0.0001), \n",
    "    dataset=dataset, \n",
    "    batch_size=16,\n",
    "    save_every=1,\n",
    "    save_name='ddpm_training_lr1e-4',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing learning rate $10^{-5}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unet( \n",
    "    unet_model, \n",
    "    n_epochs=10, \n",
    "    noise_scheduler=noise_scheduler, \n",
    "    optimizer=optim.Adam(unet_model.parameters(), lr=1e-5), \n",
    "    dataset=dataset, \n",
    "    batch_size=16,\n",
    "    save_every=1,\n",
    "    save_name='ddpm_training_lr1e-5',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from denoising_diffusion_pytorch import Unet, GaussianDiffusion, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Unet(\n",
    "#     dim = 64,\n",
    "#     dim_mults = (1, 2, 4, 8),\n",
    "# ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusion = GaussianDiffusion(\n",
    "#     model,\n",
    "#     image_size = 128,\n",
    "#     timesteps = 1000,   # number of steps\n",
    "# ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     diffusion,\n",
    "#     data_path,\n",
    "#     train_batch_size=16,\n",
    "#     train_lr=2e-5,\n",
    "#     train_num_steps=1,         # total training steps\n",
    "#     gradient_accumulate_every=2,    # gradient accumulation steps\n",
    "#     ema_decay=0.995,                # exponential moving average decay\n",
    "#     amp=True                        # turn on mixed precision\n",
    "# ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GAN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
